{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "df_train = pd.read_csv(os.path.join(cwd, 'Preprocessed_Train.csv')) # preprocessed train data\n",
    "df_test = pd.read_csv(os.path.join(cwd, 'Preprocessed_Test.csv')) # preprocessed test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = df_test['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train['comments'], df_train['subreddits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test['comments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not = pd.read_csv(os.path.join(cwd, 'reddit_train.csv'))  #not preprocessed train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_not, y_train_not = df_not['comments'], df_not['subreddits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_not = pd.read_csv(os.path.join(cwd, 'reddit_test.csv'))  #not preprocessed test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_not = df_test_not['comments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=None, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "Encoder = LabelEncoder()\n",
    "\n",
    "y_train = Encoder.fit_transform(y_train)\n",
    "X_train = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tfidf_vectorizer.transform(df_test) # preprocessed test set\n",
    "df_test_not = tfidf_vectorizer.transform(df_test_not) #not preprocessed test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_not = Encoder.fit_transform(y_train_not)\n",
    "X_train_not = tfidf_vectorizer.fit_transform(X_train_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial', max_iter=1000)\n",
    "clf2 = linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, n_iter=1000, random_state=None, learning_rate='optimal', early_stopping=False, validation_fraction=0.1, n_iter_no_change=5)\n",
    "clf3 = naive_bayes.MultinomialNB(alpha=0.2, fit_prior=True, class_prior=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=1000, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#higher accuracy\n",
    "clf1.fit(X_train_not, y_train_not)\n",
    "\n",
    "#clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
       "       n_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.2, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1],voting='hard')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model_selection.cross_val_score(eclf, X_train , y_train, cv=5,scoring='accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56935714 0.57614286 0.57185714 0.56907143 0.56968355]\n",
      "0.5712224240506976\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "print(score.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_not = model_selection.cross_val_score(eclf, X_train_not, y_train_not, cv=5, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57635714 0.57771429 0.57528571 0.57057143 0.57311237]\n",
      "0.5746081873195024\n"
     ]
    }
   ],
   "source": [
    "print(score_not)\n",
    "print(score_not.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fitting sgd on data before preprocessing and final stacked model on preprocessed data \n",
    "\n",
    "5-fold cross validation\n",
    "[0.56935714 0.576      0.57178571 0.56921429 0.56954068]\n",
    "mean = 0.5711795648668783 \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fitting sgd on data before preprocessing and final stacked model on data before preprocessing \n",
    "\n",
    "5-fold cross validation\n",
    "[0.57642857 0.57771429 0.57535714 0.57071429 0.57311237]\n",
    "mean = 0.5746653301766452\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fitting sgd on preprocessed data and final stacked model on preprocessed data \n",
    "\n",
    "5-fold cross validation\n",
    "[0.56935714 0.57592857 0.57178571 0.56907143 0.56968355]\n",
    "mean = 0.5711652811935547\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest achieved accuracy "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "fitting sgd on data before preprocessing and final stacked model on data before preprocessing \n",
    "logreg fitted on preprocessed data\n",
    "\n",
    "\n",
    "5-fold cross validation\n",
    "[0.57628571 0.57792857 0.57528571 0.57064286 0.57325523]\n",
    "mean = 0.574679617931893\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we discovered that building the model fitting sgd on data before preprocessing and final stacked model on data before preprocessing yields the highest accuracy - this score is described in the report\n",
    "\n",
    "let's fit logistic regression model with preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sgd fitted on data before preprocessing \n",
    "logistic regression fitted on preprocessed data\n",
    "\n",
    "final stacked model fitted on preprocessed data\n",
    "\n",
    "5-fold cross validation\n",
    "[0.56935714 0.57592857 0.57178571 0.56907143 0.56968355]\n",
    "mean = 0.5711652811935547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sgd fitted on data before preprocessing \n",
    "logistic regression fitted on data before preprocessing \n",
    "\n",
    "final stacked model fitted on data before preprocessing \n",
    "\n",
    "5-fold cross validation\n",
    "[0.57635714 0.57771429 0.57528571 0.57057143 0.57311237]\n",
    "mean = 0.5746081873195024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(os.path.join(cwd, 'Preprocessed_Test.csv'))\n",
    "columns_new = ['id', 'category']\n",
    "df_submit = pd.DataFrame(df_test, columns=columns_new)\n",
    "\n",
    "df_preds = pd.DataFrame(eclf_pred)\n",
    "df_preds['category'] = eclf_pred\n",
    "\n",
    "df_submit['category']= df_preds['category']\n",
    "df_submit['id'] = df_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit.to_csv('C:/Users/adamb/Desktop/COMP551 Applied Machine Learning/Project2/code/try_October15__Try.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
